{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SaW6VAaZmC5-",
        "uVcrubXDI_Fg",
        "I5LIidVO-EMF",
        "IxfXmhJe-TO6"
      ],
      "authorship_tag": "ABX9TyOehCmuE7gtNm+xDnk//K6C"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Up Environment"
      ],
      "metadata": {
        "id": "SaW6VAaZmC5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File System uploaded directly into Collab\n",
        "# Will it remain on a refresh or close and open? So far yes however you did upload the files into the directory as well\n",
        "import pandas as pd\n",
        "file = ('/content/walmart.csv')\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "\n",
        "# We have columns and indexes (0,1,2,3..)"
      ],
      "metadata": {
        "id": "VaowbOhDmQAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns= {'User_ID': 'UserID',\n",
        "                    'Product_ID': 'ProductID',\n",
        "\n",
        "\n",
        "                    'City_Category': 'City',\n",
        "       'Stay_In_Current_City_Years': 'YearsOfResidence',\n",
        "                    'Marital_Status':'MaritalStatus',\n",
        "                    'Product_Category': 'ProductCategory',\n",
        "                    'Purchase': 'ReceiptSum'})"
      ],
      "metadata": {
        "id": "RGcAIpZ3mn4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo Improvement From Median To Mean Classification"
      ],
      "metadata": {
        "id": "uVcrubXDI_Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Median MinMax Scaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].median()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkDqcFN1JGfu",
        "outputId": "25a5aab5-8413-4d43-eb99-2a8442447d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.641\n",
            "Precision: 0.641\n",
            "Recall: 0.641\n",
            "F1 Score: 0.641\n",
            "Confusion Matrix:\n",
            " [[34557 20589]\n",
            " [18929 35939]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.63      0.64     55146\n",
            "        True       0.64      0.66      0.65     54868\n",
            "\n",
            "    accuracy                           0.64    110014\n",
            "   macro avg       0.64      0.64      0.64    110014\n",
            "weighted avg       0.64      0.64      0.64    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Mean MinMaxScaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].mean()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYvkd_R2JA9Y",
        "outputId": "c6fdcffa-383e-4f88-affa-acd98fdedbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.788\n",
            "Precision: 0.789\n",
            "Recall: 0.788\n",
            "F1 Score: 0.781\n",
            "Confusion Matrix:\n",
            " [[59647  6775]\n",
            " [16599 26993]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.90      0.84     66422\n",
            "        True       0.80      0.62      0.70     43592\n",
            "\n",
            "    accuracy                           0.79    110014\n",
            "   macro avg       0.79      0.76      0.77    110014\n",
            "weighted avg       0.79      0.79      0.78    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model"
      ],
      "metadata": {
        "id": "I5LIidVO-EMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "changedX = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "\n",
        "# Label Encoding\n",
        "for column in changedX.select_dtypes(include=['object']).columns:\n",
        "    changedX[column] = pd.Categorical(changedX[column]).codes\n",
        "\n",
        "# MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "changedX_scaled = scaler.fit_transform(changedX)\n",
        "changedX_train, changedX_test, y_train, y_test = train_test_split(changedX_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(changedX_train, y_train)\n",
        "predictions_lr = lr_model.predict(changedX_test)\n",
        "mse_lr = mean_squared_error(y_test, predictions_lr)\n",
        "r2_lr = r2_score(y_test, predictions_lr)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Linear Regression Label Encoding Metrics For Sales Target:\")\n",
        "print(\"MSE:\", mse_lr)\n",
        "print(\"R^2 Score:\", r2_lr)"
      ],
      "metadata": {
        "id": "L40BQRe7nD4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94579e4d-b6bd-4cef-c6a4-25dadfc935fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Label Encoding Metrics For Sales Target:\n",
            "MSE: 22023142.515233032\n",
            "R^2 Score: 0.12349817745837499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "changedX = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "\n",
        "# One-hot encode\n",
        "changedX = pd.get_dummies(changedX, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "#MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "changedX_scaled = scaler.fit_transform(changedX)\n",
        "changedX_train, changedX_test, y_train, y_test = train_test_split(changedX_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(changedX_train, y_train)\n",
        "predictions_lr = lr_model.predict(changedX_test)\n",
        "mse_lr = mean_squared_error(y_test, predictions_lr)\n",
        "r2_lr = r2_score(y_test, predictions_lr)\n",
        "\n",
        "print(\"Linear Regression Metrics:\")\n",
        "print(\"MSE:\", mse_lr)\n",
        "print(\"R^2 Score:\", r2_lr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGsf9i0rEEnU",
        "outputId": "12a9ffb6-c5ea-4118-b3c5-6536d4a81085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Metrics:\n",
            "MSE: 22010737.371376548\n",
            "R^2 Score: 0.12399189134101352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "changedX = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "\n",
        "# One-hot encode\n",
        "changedX = pd.get_dummies(changedX, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "#RobustScaler\n",
        "scaler = RobustScaler()\n",
        "changedX_scaled = scaler.fit_transform(changedX)\n",
        "changedX_train, changedX_test, y_train, y_test = train_test_split(changedX_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(changedX_train, y_train)\n",
        "predictions_lr = lr_model.predict(changedX_test)\n",
        "mse_lr = mean_squared_error(y_test, predictions_lr)\n",
        "r2_lr = r2_score(y_test, predictions_lr)\n",
        "\n",
        "print(\"Linear Regression Metrics:\")\n",
        "print(\"MSE:\", mse_lr)\n",
        "print(\"R^2 Score:\", r2_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkCUi7c4IAZs",
        "outputId": "dc40b579-a27e-4e18-ccf7-eca9cb989f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Metrics:\n",
            "MSE: 22010737.371376716\n",
            "R^2 Score: 0.12399189134100674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\"Label Encoding\", \"One-Hot Encoding\", \"RobustScaler\"]\n",
        "mse = [22023142.5152332, 22010737.371376548, 22010737.37137616]\n",
        "r2 = [0.12348917745873499, 0.12399189134101352, 0.12399189134010674]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "bars = ax.bar(models, r2, color='b', alpha=0.6)\n",
        "\n",
        "for bar, mse_value in zip(bars, mse):\n",
        "    yval = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, yval, f'MSE: { mse_value:.2f}',\n",
        "            verticalalignment='bottom', ha='center')\n",
        "\n",
        "\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('R2 Score')\n",
        "ax.set_title('Linear Regression Comparison of R2 and MSE')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "bziOyh3DSbv0",
        "outputId": "1b4bc324-0a4a-4741-a35e-dd53cd4409f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZuCVL7qwRXDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Models"
      ],
      "metadata": {
        "id": "IxfXmhJe-TO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WORKING HERE"
      ],
      "metadata": {
        "id": "bgcSFCwv0Y5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Using Median\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].median()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dqZ1QRb3Ji3",
        "outputId": "0348a15d-f4f2-425b-c991-194d8fa2c8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.640\n",
            "Precision: 0.640\n",
            "Recall: 0.640\n",
            "F1 Score: 0.640\n",
            "Confusion Matrix:\n",
            " [[34501 20645]\n",
            " [18940 35928]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.63      0.64     55146\n",
            "        True       0.64      0.65      0.64     54868\n",
            "\n",
            "    accuracy                           0.64    110014\n",
            "   macro avg       0.64      0.64      0.64    110014\n",
            "weighted avg       0.64      0.64      0.64    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing increasing iterations using Median\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].median()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='binary')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INYPCnU6Brur",
        "outputId": "b361a68f-79ae-46dd-8919-14bb1fe35bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.640\n",
            "Precision: 0.640\n",
            "Recall: 0.655\n",
            "F1 Score: 0.640\n",
            "Confusion Matrix:\n",
            " [[34487 20659]\n",
            " [18924 35944]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.63      0.64     55146\n",
            "        True       0.64      0.66      0.64     54868\n",
            "\n",
            "    accuracy                           0.64    110014\n",
            "   macro avg       0.64      0.64      0.64    110014\n",
            "weighted avg       0.64      0.64      0.64    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "#Testing Mean\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].mean()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qGOJlSx-k43",
        "outputId": "71c5b151-d99b-4d03-ba0e-911045cecb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.788\n",
            "Precision: 0.789\n",
            "Recall: 0.788\n",
            "F1 Score: 0.781\n",
            "Confusion Matrix:\n",
            " [[59654  6768]\n",
            " [16598 26994]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.90      0.84     66422\n",
            "        True       0.80      0.62      0.70     43592\n",
            "\n",
            "    accuracy                           0.79    110014\n",
            "   macro avg       0.79      0.76      0.77    110014\n",
            "weighted avg       0.79      0.79      0.78    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Median Standard Scaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].median()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZATCyVZkASip",
        "outputId": "11e4ebeb-698e-4576-e9e2-e7ba21ae7958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.640\n",
            "Precision: 0.640\n",
            "Recall: 0.640\n",
            "F1 Score: 0.640\n",
            "Confusion Matrix:\n",
            " [[34474 20672]\n",
            " [18925 35943]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.63      0.64     55146\n",
            "        True       0.63      0.66      0.64     54868\n",
            "\n",
            "    accuracy                           0.64    110014\n",
            "   macro avg       0.64      0.64      0.64    110014\n",
            "weighted avg       0.64      0.64      0.64    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Median MinMax Scaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].median()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dY2ck5tloZ7",
        "outputId": "bbec8b69-b5cd-48de-b0e4-2356f1a7445e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.641\n",
            "Precision: 0.641\n",
            "Recall: 0.641\n",
            "F1 Score: 0.641\n",
            "Confusion Matrix:\n",
            " [[34557 20589]\n",
            " [18929 35939]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.63      0.64     55146\n",
            "        True       0.64      0.66      0.65     54868\n",
            "\n",
            "    accuracy                           0.64    110014\n",
            "   macro avg       0.64      0.64      0.64    110014\n",
            "weighted avg       0.64      0.64      0.64    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Mean MinMaxScaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].mean()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWLPgDjZBJOV",
        "outputId": "fea4e069-f5fb-42b3-efaf-2aad421c16bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.788\n",
            "Precision: 0.789\n",
            "Recall: 0.788\n",
            "F1 Score: 0.781\n",
            "Confusion Matrix:\n",
            " [[59647  6775]\n",
            " [16599 26993]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.90      0.84     66422\n",
            "        True       0.80      0.62      0.70     43592\n",
            "\n",
            "    accuracy                           0.79    110014\n",
            "   macro avg       0.79      0.76      0.77    110014\n",
            "weighted avg       0.79      0.79      0.78    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Mean Standard Scaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].mean()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision : {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCYfx57kgRjt",
        "outputId": "7cda8df7-46dc-4299-c919-0f5d0deb1e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.788\n",
            "Precision: 0.789\n",
            "Recall: 0.788\n",
            "F1 Score: 0.781\n",
            "Confusion Matrix:\n",
            " [[59653  6769]\n",
            " [16598 26994]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.90      0.84     66422\n",
            "        True       0.80      0.62      0.70     43592\n",
            "\n",
            "    accuracy                           0.79    110014\n",
            "   macro avg       0.79      0.76      0.77    110014\n",
            "weighted avg       0.79      0.79      0.78    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Mean RobustScaler Scaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "XLogisticRegression = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum'] > df['ReceiptSum'].mean()  # Categorize as high (1) or low (0) spending\n",
        "#y=y.squeeze()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "XLogisticRegression = pd.get_dummies(XLogisticRegression, drop_first=True)  # drop_first to avoid dummy variable trap\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XLogisticRegression, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "#mse = mean_squared_error(y_test, y_pred)\n",
        "#r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the results\n",
        "#print(\"Mean Squared Error (MSE):\", mse)\n",
        "#print(\"R-squared (R²):\", r2)\n",
        "#print(\"Y Intercept:\", intercept)\n",
        "#print(\"Coefficients:\", coefficients)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1 Score: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxQZLOSigxMR",
        "outputId": "36ab16c0-929f-4fab-9bfc-e2e222822a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.788\n",
            "Precision: 0.789\n",
            "Recall: 0.788\n",
            "F1 Score: 0.781\n",
            "Confusion Matrix:\n",
            " [[59646  6776]\n",
            " [16594 26998]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.90      0.84     66422\n",
            "        True       0.80      0.62      0.70     43592\n",
            "\n",
            "    accuracy                           0.79    110014\n",
            "   macro avg       0.79      0.76      0.77    110014\n",
            "weighted avg       0.79      0.79      0.78    110014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trees"
      ],
      "metadata": {
        "id": "zWIMvK9uJVe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "XDecisionTreeRegressor = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "# One-hot\n",
        "XDecisionTreeRegressor = pd.get_dummies(XDecisionTreeRegressor, drop_first=True)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(XDecisionTreeRegressor, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnZkXuaMKdjo",
        "outputId": "179d4f05-8407-419d-8984-1e63bb1282da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 8950520.859929599\n",
            "R-squared (R²): 0.6437770930738531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "XDecisionTreeRegressor = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "# One-hot\n",
        "XDecisionTreeRegressor = pd.get_dummies(XDecisionTreeRegressor, drop_first=True)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XDecisionTreeRegressor, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-s3PgGiLhmR",
        "outputId": "f9d1c65c-48b1-4964-bb12-a088e827fd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 8950520.859929599\n",
            "R-squared (R²): 0.6437770930738531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Non linear relationships in data and wide range of receipt values i.e. 12- 25k"
      ],
      "metadata": {
        "id": "i2-xQi1VLhor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "XDecisionTreeRegressor = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "# One-hot\n",
        "XDecisionTreeRegressor = pd.get_dummies(XDecisionTreeRegressor, drop_first=True)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XDecisionTreeRegressor, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt2MU5N9Lh00",
        "outputId": "e9076265-fbbe-44e1-eac3-29e45db7ba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 8950520.859929599\n",
            "R-squared (R²): 0.6437770930738531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "XDecisionTreeRegressor = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "# One hot\n",
        "XDecisionTreeRegressor = pd.get_dummies(XDecisionTreeRegressor, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(XDecisionTreeRegressor, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"Decision Tree Regressor Results:\")\n",
        "\n",
        "print(\"mean_absolute_error:\", MAE)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWDIZmbyLh24",
        "outputId": "72055486-211f-4404-ea71-1c25f1cea365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor Results:\n",
            "mean_absolute_error: 2185.090939720006\n",
            "Mean Squared Error (MSE): 8950520.859929599\n",
            "R-squared (R²): 0.6437770930738531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55gngJD9ReIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train_scaled, y_train)\n",
        "y_pred = random_forest_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Random Forest Regressor Results:\")\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"mean_absolute_error:\", MAE)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsoZqCx_ReKd",
        "outputId": "8a64851a-03d0-4d05-95a2-1aa091ca8bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Results:\n",
            "mean_absolute_error: 2171.981572069039\n",
            "Mean Squared Error (MSE): 8745856.107834546\n",
            "R-squared (R²): 0.6519225713178076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ceJDhkmReNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X = df.drop(['ReceiptSum', 'UserID', 'ProductID'], axis=1)\n",
        "y = df['ReceiptSum']\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "gradient_boosting_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gradient_boosting_model.fit(X_train_scaled, y_train)\n",
        "y_pred = gradient_boosting_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Gradient Boosting Regressor Results:\")\n",
        "print(\"mean_absolute_error:\", MAE)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXnuCmCuRegF",
        "outputId": "cf23274a-ce4f-429a-9e92-39871ca0930f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor Results:\n",
            "mean_absolute_error: 2289.340348444576\n",
            "Mean Squared Error (MSE): 9166417.23620022\n",
            "R-squared (R²): 0.6351846060048327\n"
          ]
        }
      ]
    }
  ]
}